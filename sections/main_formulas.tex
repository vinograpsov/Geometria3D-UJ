\section{Formulas}


Długość wektora \( \mathbf{V} \) jest określona jako:
\[
\|\mathbf{V}\| = \sqrt{V_x^2 + V_y^2 + V_z^2}
\]
\textbf{Opis:} Ten wzór pozwala obliczyć długość (moduł) wektora w przestrzeni trójwymiarowej, używając jego współrzędnych \( V_x \), \( V_y \), \( V_z \).

\vspace{1em}
\noindent
Iloczyn skalarny dwóch wektorów \( \mathbf{V} \) i \( \mathbf{W} \) jest określony jako:

\[
\mathbf{V} \cdot \mathbf{W} = V_x W_x + V_y W_y + V_z W_z
\]
\noindent
\textbf{Opis:} Ten wzór oblicza iloczyn skalarny (dot product) dwóch wektorów w przestrzeni trójwymiarowej, mnożąc odpowiadające sobie współrzędne \( V_x \), \( W_x \), \( V_y \), \( W_y \), \( V_z \), \( W_z \) i sumując wyniki.


\vspace{1em}
\noindent
Iloczyn wektorowy dwóch wektorów \( \mathbf{V} \) i \( \mathbf{W} \) jest określony jako:

\[
\mathbf{V} \times \mathbf{W} = 
\begin{bmatrix}
V_y W_z - V_z W_y \\
V_z W_x - V_x W_z \\
V_x W_y - V_y W_x
\end{bmatrix}
\]

\vspace{1em}
\noindent
\textbf{Opis:} Iloczyn wektorowy (cross product) dwóch wektorów w przestrzeni trójwymiarowej tworzy nowy wektor, który jest prostopadły do płaszczyzny utworzonej przez \( \mathbf{V} \) i \( \mathbf{W} \). Składniki nowego wektora są obliczane na podstawie powyższego wzoru.



\vspace{1em}
\noindent
Rzut wektora \( \mathbf{W} \) na \( \mathbf{V} \) jest określony jako:

\[
\text{proj}_{\mathbf{V}} \mathbf{W} = \frac{\mathbf{V} \cdot \mathbf{W}}{\|\mathbf{V}\|^2} \mathbf{V}
\]

\vspace{1em}
\noindent
\textbf{Opis:} Rzut wektora \( \mathbf{W} \) na \( \mathbf{V} \) to wektor będący projekcją \( \mathbf{W} \) na kierunek \( \mathbf{V} \).




\vspace{1em}
\noindent
Każdy układ liniowo niezależnych wektorów \( \mathbf{U}, \mathbf{V} \) i \( \mathbf{W} \) można przekształcić w ortonormalny układ \( \mathbf{u}, \mathbf{v}, \mathbf{w} \) za pomocą algorytmu ortonormalizacji Grama-Schmidta:

\[
\mathbf{u} = \frac{\mathbf{U}}{\|\mathbf{U}\|}
\]

\[
\mathbf{v} = \frac{\mathbf{V} - \text{proj}_{\mathbf{u}} \mathbf{V}}{\|\mathbf{V} - \text{proj}_{\mathbf{u}} \mathbf{V}\|}
\]

\[
\mathbf{w} = \frac{\mathbf{W} - \text{proj}_{\mathbf{u}} \mathbf{W} - \text{proj}_{\mathbf{v}} \mathbf{W}}{\|\mathbf{W} - \text{proj}_{\mathbf{u}} \mathbf{W} - \text{proj}_{\mathbf{v}} \mathbf{W}\|}
\]

\vspace{1em}
\noindent
\textbf{Opis:} Algorytm ortonormalizacji Grama-Schmidta służy do przekształcenia układu liniowo niezależnych wektorów w układ ortonormalny (wektory wzajemnie prostopadłe o długości 1). Proces polega na:
- Normalizacji pierwszego wektora \( \mathbf{U} \),
- Usuwaniu rzutów kolejnych wektorów na wcześniejsze i normalizacji powstałych wyników.



% % not confident about this
% rework 
% \vspace{1em}
% \noindent
% Diagonalizacja Macierzy
% Wyznacznik macierzy \( M - \lambda I \) jest obliczany jako:

% \[
% \text{det}(M - \lambda I) = 
% \begin{vmatrix}
% 1 - \lambda & 0 & 1 \\
% 0 & 1 - \lambda & 0 \\
% 1 & 0 & 1 - \lambda
% \end{vmatrix}
% \]

% \vspace{1em}
% \noindent
% \textbf{Opis:} Wzór ten przedstawia wyznacznik macierzy \( M - \lambda I \), gdzie \( \lambda \) to wartość własna (eigenvalue), a \( I \) to macierz jednostkowa. Wyznacznik jest wykorzystywany w obliczaniu wartości własnych macierzy oraz w analizie jej własności algebraicznych.



\vspace{1em}
\noindent
Wyznacznik macierzy \( 3 \times 3 \) można rozwinąć wzdłuż pierwszego wiersza w następujący sposób:

% need to make better formatting
\begin{multline*}
    \begin{vmatrix}
    M_{xx} & M_{xy} & M_{xz} \\
    M_{yx} & M_{yy} & M_{yz} \\
    M_{zx} & M_{zy} & M_{zz}
    \end{vmatrix}
    =
    M_{xx}(-1)^{1+1}
    \begin{vmatrix}
    M_{yy} & M_{yz} \\
    M_{zy} & M_{zz}
    \end{vmatrix} \\
    + M_{xy}(-1)^{1+2}
    \begin{vmatrix}
    M_{yx} & M_{yz} \\
    M_{zx} & M_{zz}
    \end{vmatrix}
    + M_{xz}(-1)^{1+3}
    \begin{vmatrix}
    M_{yx} & M_{yy} \\
    M_{zx} & M_{zy}
    \end{vmatrix}
    \end{multline*}
    
    \begin{align*}
    &= M_{xx}M_{yy}M_{zz} - M_{xx}M_{yz}M_{zy} \\
    &\quad - M_{xy}M_{yx}M_{zz} + M_{xy}M_{yz}M_{zx} \\
    &\quad + M_{xz}M_{yx}M_{zy} - M_{xz}M_{yy}M_{zx}
    \end{align*}

\vspace{1em}
\noindent
\textbf{Opis:} Wyznacznik macierzy \( 3 \times 3 \) oblicza się, rozwijając go wzdłuż wiersza lub kolumny. Wzór ten przedstawia rozwinięcie wzdłuż pierwszego wiersza z zastosowaniem wyznaczników macierzy \( 2 \times 2 \) dla odpowiednich podmacierzy.




% need to make better formatting
\vspace{1em}
\noindent
Iloczyn dwóch macierzy \( M \) i \( K \) można zapisać jako:

\[
\resizebox{\textwidth}{!}{$
MK =
\begin{pmatrix}
M_{xx}K_{xx} + M_{xy}K_{yx} + M_{xz}K_{zx} & M_{xx}K_{xy} + M_{xy}K_{yy} + M_{xz}K_{zy} & M_{xx}K_{xz} + M_{xy}K_{yz} + M_{xz}K_{zz} \\
M_{yx}K_{xx} + M_{yy}K_{yx} + M_{yz}K_{zx} & M_{yx}K_{xy} + M_{yy}K_{yy} + M_{yz}K_{zy} & M_{yx}K_{xz} + M_{yy}K_{yz} + M_{yz}K_{zz} \\
M_{zx}K_{xx} + M_{zy}K_{yx} + M_{zz}K_{zx} & M_{zx}K_{xy} + M_{zy}K_{yy} + M_{zz}K_{zy} & M_{zx}K_{xz} + M_{zy}K_{yz} + M_{zz}K_{zz}
\end{pmatrix}
$}
\]


\vspace{1em}
\noindent
\textbf{Opis:} Iloczyn dwóch macierzy \( M \) i \( K \) oblicza się jako sumę iloczynów odpowiednich wierszy macierzy \( M \) i kolumn macierzy \( K \). Wynikiem jest nowa macierz, której elementy są obliczane zgodnie z powyższym wzorem.

\vspace{1em}
\noindent
\textbf{Metoda Gaussa--Jordana}


\[
\left[
\begin{array}{c|c}
M & I
\end{array}
\right]
\;\xrightarrow{\text{operacje elementarne}}
\left[
\begin{array}{c|c}
I & M^{-1}
\end{array}
\right].
\]

\vspace{1em}
\noindent
\textbf{Opis:} 
Metoda Gaussa--Jordana polega na dołączeniu do macierzy $M$ macierzy jednostkowej $I$ (w postaci rozszerzonej) i wykonaniu na niej elementarnych operacji na wierszach. Po sprowadzeniu lewej strony do $I$, prawa strona staje się macierzą odwrotną $M^{-1}$.


\textbf{Przykład (niewielka macierz $2 \times 2$)}

Rozważmy macierz:
\[
M \;=\;
\begin{pmatrix}
1 & 2 \\
3 & 4
\end{pmatrix}.
\]
Aby znaleźć $M^{-1}$ metodą Gaussa--Jordana, tworzymy macierz rozszerzoną:
\[
\left[
\begin{array}{cc|cc}
1 & 2 & 1 & 0 \\
3 & 4 & 0 & 1
\end{array}
\right].
\]

\noindent
\textbf{Krok 1.} Wyzeruj elementy poniżej pierwszego przegubowego (tzw. pivotu) w pierwszej kolumnie:
\[
R_2 \,\leftarrow\, R_2 - 3\,R_1,
\]
co daje:
\[
\left[
\begin{array}{cc|cc}
1 & 2 & 1 & 0 \\
0 & -2 & -3 & 1
\end{array}
\right].
\]

\noindent
\textbf{Krok 2.} Unormuj drugi wiersz (aby mieć jedynkę na przekątnej):
\[
R_2 \,\leftarrow\, -\tfrac12\,R_2
\;\;\Longrightarrow\;\;
\left[
\begin{array}{cc|cc}
1 & 2 & 1 & 0 \\
0 & 1 & \tfrac32 & -\tfrac12
\end{array}
\right].
\]

\noindent
\textbf{Krok 3.} Wyzeruj element powyżej nowego pivotu (w pierwszym wierszu, drugim \mbox{stolcu}):
\[
R_1 \,\leftarrow\, R_1 - 2\,R_2,
\]
czyli
\[
\left[
\begin{array}{cc|cc}
1 & 0 & 1 - 2\cdot\tfrac32 & 0 - 2\cdot\bigl(-\tfrac12\bigr) \\
0 & 1 & \tfrac32 & -\tfrac12
\end{array}
\right]
=
\left[
\begin{array}{cc|cc}
1 & 0 & -2 & 1 \\
0 & 1 & \tfrac32 & -\tfrac12
\end{array}
\right].
\]

\noindent
\textbf{Wynik:} Po lewej stronie mamy macierz jednostkową, a po prawej macierz odwrotną $M^{-1}$:
\[
M^{-1} 
\;=\;
\begin{pmatrix}
-2 & 1 \\
\tfrac{3}{2} & -\tfrac{1}{2}
\end{pmatrix}.
\]





\vspace{1em}
\noindent
Macierze obrotu o kąt \(\theta\) w przestrzeni trójwymiarowej:

\[
R_x(\theta) \;=\;
\begin{pmatrix}
1 & 0 & 0 \\
0 & \cos\theta & -\sin\theta \\
0 & \sin\theta & \cos\theta
\end{pmatrix},
\quad
R_y(\theta) \;=\;
\begin{pmatrix}
\cos\theta & 0 & \sin\theta \\
0 & 1 & 0 \\
-\sin\theta & 0 & \cos\theta
\end{pmatrix},
\quad
R_z(\theta) \;=\;
\begin{pmatrix}
\cos\theta & -\sin\theta & 0 \\
\sin\theta & \cos\theta & 0 \\
0 & 0 & 1
\end{pmatrix}.
\]

\noindent
\textbf{Opis:} Powyższe macierze reprezentują obroty o kąt \(\theta\) wokół kolejno osi \(x\), \(y\) i~\(z\). Każda z nich może służyć do transformacji wektorów w~\(\mathbb{R}^3\) w~celu wykonania obrotu o~zadany kąt wokół wskazanej osi.





% -------------- Diagonalizacja macierzy ----------------

\vspace{1em}
\noindent

Diagonalizacja macierzy \(M\) polega na znalezieniu takiej macierzy przejścia \(P\) oraz macierzy diagonalnej \(D\), aby zachodziła równość:
\[
M \;=\; P \,D\, P^{-1}.
\]
Macierz diagonalna \(D\) zawiera wartości własne (ang.~\emph{eigenvalues}) macierzy \(M\) na głównej przekątnej, natomiast kolumny macierzy \(P\) są wektorami własnymi (ang.~\emph{eigenvectors}) odpowiadającymi tym wartościom własnym.


\begin{figure}[h!]
    \centering
    \begin{equation*}
    \det(M - \lambda I) 
    \;=\;
    \begin{vmatrix}
    1 - \lambda & 0 & 1 \\
    0 & 1 - \lambda & 0 \\
    1 & 0 & 1 - \lambda
    \end{vmatrix}.
    \end{equation*}
    \caption{Wyznacznik macierzy $(M - \lambda I)$ dla przykładowej macierzy $3\times3$.}
    \label{fig:matrix-determinant}
\end{figure}


Przykład diagonalizacji prostej macierzy \(2 \times 2\)

Rozważmy macierz:
\[
M \;=\;
\begin{pmatrix}
2 & 1 \\
0 & 3
\end{pmatrix}.
\]
Chcemy znaleźć taką macierz \(P\) i macierz diagonalną \(D\), aby:
\[
M = P\,D\,P^{-1}.
\]

\paragraph{Krok 1: Znalezienie wartości własnych.}
Wartości własne \(\lambda\) otrzymujemy, rozwiązując równanie:
\[
\det(M - \lambda I) \;=\; 0.
\]
W naszym przypadku:
\[
M - \lambda I \;=\;
\begin{pmatrix}
2-\lambda & 1 \\
0 & 3-\lambda
\end{pmatrix}.
\]
Zatem:
\[
\det(M - \lambda I) 
\;=\; (2-\lambda)(3-\lambda) - (1 \cdot 0)
\;=\; (2-\lambda)(3-\lambda).
\]
Równanie \(\det(M - \lambda I) = 0\) daje:
\[
(2-\lambda)(3-\lambda) = 0
\;\;\Longrightarrow\;\;
\lambda_1 = 2, 
\quad \lambda_2 = 3.
\]

\paragraph{Krok 2: Znalezienie wektorów własnych.}
Dla każdej wartości własnej \(\lambda_i\) rozwiązujemy układ:
\[
(M - \lambda_i I)\mathbf{v}_i = \mathbf{0},
\]
aby otrzymać wektor własny \(\mathbf{v}_i\).

\subparagraph{Dla \(\lambda_1 = 2\):}
\[
M - 2I 
\;=\;
\begin{pmatrix}
2-2 & 1 \\
0 & 3-2
\end{pmatrix}
\;=\;
\begin{pmatrix}
0 & 1 \\
0 & 1
\end{pmatrix}.
\]
Układ \(\begin{pmatrix}0 & 1\\0 & 1\end{pmatrix} \begin{pmatrix}v_x\\v_y\end{pmatrix} = \begin{pmatrix}0\\0\end{pmatrix}\)
oznacza, że \(v_y = 0\). Nie ma warunku na \(v_x\), więc bierzemy \(v_x = 1\). 
Zatem wektor własny:
\[
\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}.
\]

\subparagraph{Dla \(\lambda_2 = 3\):}
\[
M - 3I 
\;=\;
\begin{pmatrix}
2-3 & 1 \\
0 & 3-3
\end{pmatrix}
\;=\;
\begin{pmatrix}
-1 & 1 \\
0  & 0
\end{pmatrix}.
\]
Układ \(\begin{pmatrix}-1 & 1\\0 & 0\end{pmatrix}\begin{pmatrix}v_x\\v_y\end{pmatrix} = \begin{pmatrix}0\\0\end{pmatrix}\)
daje równość \(-v_x + v_y = 0\), czyli \(v_y = v_x\). Możemy wybrać \(v_x = 1\), wtedy \(v_y = 1\).
Zatem wektor własny:
\[
\mathbf{v}_2 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}.
\]

\paragraph{Krok 3: Zbudowanie macierzy \(P\) i macierzy \(D\).}
Kolumny macierzy \(P\) to wektory własne \(\mathbf{v}_1, \mathbf{v}_2\). Zatem:
\[
P \;=\;
\begin{pmatrix}
1 & 1 \\
0 & 1
\end{pmatrix}.
\]
Macierz diagonalna \(D\) zawiera wartości własne \(\lambda_1, \lambda_2\) na głównej przekątnej (w tej samej kolejności co kolumny w \(P\)):
\[
D \;=\;
\begin{pmatrix}
2 & 0 \\
0 & 3
\end{pmatrix}.
\]

\paragraph{Krok 4: Sprawdzenie równości \(M = P D P^{-1}\).}
Aby potwierdzić, że faktycznie zachodzi diagonalizacja, można obliczyć:
\[
P\,D\,P^{-1}
\quad\text{oraz porównać z}\quad
M.
\]
W przypadku poprawnego doboru \(P\) i \(D\) otrzymamy dokładnie macierz \(M\).

% -------------- Diagonalizacja macierzy ----------------




\vspace{1em}
\noindent
Macierz skalowania w trójwymiarowej przestrzeni można zapisać jako:
\[
S(\alpha,\beta,\gamma) 
\;=\;
\begin{pmatrix}
\alpha & 0      & 0 \\
0      & \beta  & 0 \\
0      & 0      & \gamma
\end{pmatrix},
\]
gdzie \(\alpha,\beta,\gamma\) to dodatnie liczby rzeczywiste.

\bigskip
\noindent
Działanie tej transformacji na wektor \(\mathbf{V} = (V_x, V_y, V_z)^\top\) daje wektor
\[
\mathbf{V}' \;=\; S(\alpha,\beta,\gamma)\,\mathbf{V}
\;=\;
\begin{pmatrix}
\alpha\,V_x \\
\beta\,V_y \\
\gamma\,V_z
\end{pmatrix}.
\]


\[
\text{Niech prosta będzie zadana przez punkt } S \text{ i wektor kierunkowy } V.
\]
\[
\text{Jeżeli } P \text{ to punkt w przestrzeni, to jego odległość od tej prostej wynosi:}
\quad
d \;=\; \frac{\|(P - S)\times V\|}{\|V\|}.
\]
\[
\text{W powyższym wzorze: }
(P-S)\times V \text{ oznacza iloczyn wektorowy, }
\|\cdot\|\text{ - normę (długość) wektora.}
\]


